{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44c2ddf6",
   "metadata": {},
   "source": [
    "# Notebook of Transformer Experiments for the Shared Task Challenge\n",
    "\n",
    "Authors: Hadi Asghari & Freya Hewett\n",
    "Date:   June 2022\n",
    "\n",
    "V3 builds upon v1/v2 along with kfold cross validation\n",
    "\n",
    "**Story so far**:\n",
    "- Our best transformer so far was an xlm-roberta-base transformer with a regressor layer on top (nb v1/v2)\n",
    "- Using 80:20 split we achieved an RSME score of 0.60 on the best model.  (This translated to rmse_map of 0.48 on the public test data)\n",
    "- In this notebook we use kfold validation (with K=5). So we shall end up with n models...\n",
    "- Future: lets also experiment with xlm-roberta-large, but for now my GPU cannot handle more) \n",
    "\n",
    "\n",
    "**Competition background**:\n",
    "- https://github.com/babaknaderi/TextComplexityDE\n",
    "- https://codalab.lisn.upsaclay.fr/competitions/4964\n",
    "\n",
    "**Transformer finetuning inspiration**:\n",
    "- https://github.com/kozodoi/Text_Readability_Prediction\n",
    "- https://huggingface.co/course/chapter3/3?fw=pt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec703bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU/CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "# This is just FYI; GPU details are handled by HF's Trainer \n",
    "import torch\n",
    "print(\"GPU/CUDA available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c681d611",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-523f5d74073b9b87\n",
      "Reusing dataset csv (/home/hadi/.cache/huggingface/datasets/csv/default-523f5d74073b9b87/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3367e6ee382347e78774a16d9dcf6f72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 of:\n",
      " DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['idx', 'sentence', 'label'],\n",
      "        num_rows: 800\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['idx', 'sentence', 'label'],\n",
      "        num_rows: 200\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: LOAD TRAINING SET AND SLICE IT ACCORDINGLY \n",
    "# note: the trainsingset's CSV files header needs to be: idx, sentence, label!!  \n",
    "\n",
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "dataset_all = load_dataset(\n",
    "    \"csv\", \n",
    "    data_files= {\"train\": \"public_data_text_complexity22/training_set.csv\",},\n",
    "    sep=\",\"\n",
    ")['train']\n",
    "\n",
    "K = 5\n",
    "fold_datasets = []\n",
    "num_val_samples = len(dataset_all) // K\n",
    "\n",
    "for i in range(K):\n",
    "    # one may wish to add some shuffling somewhere somehow :)\n",
    "    val_idx = list(range(i*num_val_samples, (i+1)*num_val_samples))\n",
    "    train_idx = list(range(i*num_val_samples)) + list(range((i+1)*num_val_samples,len(dataset_all)))\n",
    "    assert len(set(val_idx) & set(train_idx)) == 0   # sanity check :)\n",
    "\n",
    "    ds = DatasetDict({\n",
    "        \"train\":dataset_all.select(train_idx),\n",
    "        \"validation\":dataset_all.select(val_idx),\n",
    "    })\n",
    "    fold_datasets.append(ds)\n",
    "\n",
    "print(len(fold_datasets), \"of:\\n\", fold_datasets[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "918a588d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2A. LOAD THE PROPER TOKENIZER IN PREPRATION FOR APPLYING TO OUR DATA. \n",
    "\n",
    "from transformers import XLMRobertaTokenizer \n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "\n",
    "# also needs a datacollator.\n",
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")\n",
    "\n",
    "# and a mapping function which will be called later. important both padding&truncation:True. \n",
    "def tokenize_function(x):\n",
    "    return tokenizer(x[\"sentence\"], padding=True, truncation=True)  # is_split_into_words=False?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "948b545a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2B. Construct our model: XLM-R with a new head regressor layer\n",
    "# Notes:\n",
    "# - The base model's .forward() can take more parameters but for training I think these are what matter\n",
    "# - One can make the layers more compelx in future versions by accessing hidden state and concating them\n",
    "# - For speed/memory, one could also freeze some of the earlier layers (not necessary now)\n",
    "\n",
    "import torch.nn as nn\n",
    "from transformers import XLMRobertaModel\n",
    "from transformers import Trainer    \n",
    "    \n",
    "    \n",
    "class TheModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.base_model = XLMRobertaModel.from_pretrained(\"xlm-roberta-base\")\n",
    "        self.dropout = nn.Dropout(0.20)  # a bit slower at start but less zigzagy val-loss in training :)\n",
    "        self.regressor = nn.Linear(768, 1)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask=None, return_dict=False):\n",
    "        assert not return_dict\n",
    "        raw_output = self.base_model(input_ids, attention_mask, return_dict=True)  \n",
    "        output = raw_output[\"pooler_output\"]  # shape is [batch_size, 768]\n",
    "        output = self.dropout(output)\n",
    "        output = self.regressor(output)\n",
    "        return output\n",
    "    \n",
    "    \n",
    "# we need a custom train because our loss function is different (RMSE)    \n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(inputs[\"input_ids\"], inputs[\"attention_mask\"])  # forward pass\n",
    "        outputs = outputs.squeeze()  # neccessary to avoid diff dims/size errors\n",
    "        loss = torch.sqrt(nn.MSELoss()(outputs, labels)) \n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f59d0027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3: THE ACTUAL TRAINING!\n",
    "# Notes, \n",
    "# - we run this one at a time, since our GPU will probably run out of ram, and we want to restart this.... \n",
    "#   TODO: if I could get the GPU To release it's memory at the end, we could easily automate this loop :)\n",
    "# - there are training platos (in terms of val-loss/over-fitting) between epoch 10-20; trainer saves the best\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "n = 0\n",
    "EPOCHS = 10  #  seems sufficient given the final RSME\n",
    "\n",
    "if n > 0:\n",
    "    assert n <= K  # sanity\n",
    "    fold_dataset = fold_datasets[n-1]\n",
    "    tokenized_dataset = fold_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "    model = TheModel()  # instantiate new one\n",
    "\n",
    "    trainer = CustomTrainer(\n",
    "        model=model,\n",
    "        args=TrainingArguments(\n",
    "                num_train_epochs=EPOCHS,  \n",
    "                output_dir=f\"checkpoints/train-xlmrreg-n{n}\",     \n",
    "                overwrite_output_dir=True,\n",
    "                logging_strategy=\"epoch\",\n",
    "                evaluation_strategy=\"epoch\",\n",
    "                save_strategy=\"epoch\",\n",
    "                save_total_limit=2,\n",
    "                load_best_model_at_end=True,\n",
    "        ),\n",
    "        train_dataset=tokenized_dataset[\"train\"],\n",
    "        eval_dataset=tokenized_dataset[\"validation\"],\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "\n",
    "    trainer.train()  # yay!\n",
    "\n",
    "    # pickle it -- 1.1GB each :O\n",
    "    import pickle\n",
    "    print(\"pickling\", end=\"..\")\n",
    "    model.to(\"cpu\")  # perhaps so it can be properly picked\n",
    "    pickle.dump(model, open(f\"checkpoints/model-xlmrreg-n{n}.p\", \"wb\"))\n",
    "    print(\".!\")\n",
    "    \n",
    "    \n",
    "# Loading best model from checkpoints/train-xlmrreg-n1/checkpoint-300 (score: 0.5455247759819031). \n",
    "# Loading best model from checkpoints/train-xlmrreg-n2/checkpoint-900 (score: 0.6186634302139282).\n",
    "# Loading best model from checkpoints/train-xlmrreg-n3/checkpoint-800 (score: 0.7035192847251892). \n",
    "# Loading best model from checkpoints/train-xlmrreg-n4/checkpoint-1000 (score: 0.5991728901863098). \n",
    "# Loading best model from checkpoints/train-xlmrreg-n5/checkpoint-900 (score: 0.645281970500946). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2313f020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 models\n"
     ]
    }
   ],
   "source": [
    "# STEP 4A: LETS RELOAD ALL THREE MODELS TO CALCULATE ENSEMBLE RMSE :)\n",
    "\n",
    "assert n == 0  # don't run this cell until training fully done\n",
    "\n",
    "import pickle\n",
    "models = []\n",
    "\n",
    "for i in range(K):\n",
    "    model = pickle.load(open(f\"checkpoints-20220702/model-xlmrreg-n{i+1}.p\", \"rb\"))\n",
    "    model.eval()  # evaluation (inference) mode\n",
    "    models.append(model)\n",
    "\n",
    "    \n",
    "print(\"Loaded\", K, \"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1909351",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hadi/.cache/huggingface/datasets/csv/default-523f5d74073b9b87/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-33d69d9f7f36f451.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.7 ms, sys: 0 ns, total: 17.7 ms\n",
      "Wall time: 15.6 ms\n",
      "CPU times: user 32.6 ms, sys: 0 ns, total: 32.6 ms\n",
      "Wall time: 33.1 ms\n",
      "CPU times: user 31.2 ms, sys: 0 ns, total: 31.2 ms\n",
      "Wall time: 31.2 ms\n",
      "0....0.4972061220307628\n",
      "1....0.35702121329234604\n",
      "2....0.4064348121115841\n",
      "3....0.3277875091084862\n",
      "4....0.4385743332602079\n"
     ]
    }
   ],
   "source": [
    "# STEP 4B: CALCULATE RMSE FOR WHOLESET. \n",
    "# note: using method below, instead of `trainer.predict` (for some reason that removes the first element of each batch)\n",
    "# more info: https://discuss.huggingface.co/t/evalprediction-returning-one-less-prediction-than-label-id-for-each-batch/6958/7\n",
    "\n",
    "import torch  \n",
    "import numpy as np\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(y_pred - y_true)))    \n",
    "\n",
    "tokenized_dataset = dataset_all.map(tokenize_function, batched=True)\n",
    "feat_inputs = torch.tensor(tokenized_dataset['input_ids'])\n",
    "feat_attns = torch.tensor(tokenized_dataset['attention_mask'])\n",
    "truth = np.array(dataset_all[\"label\"])\n",
    "print(feat_inputs.shape, feat_attns.shape, truth.shape)\n",
    "\n",
    "l_preds = []\n",
    "for i in range(K):\n",
    "    model = models[i]    \n",
    "    print(i+1, end=\"..\")\n",
    "    # wierd how slow this is?! it also uses about 70GB RAM :/ maybe needs some batching, or GPU with model out-of-eval\n",
    "    %time preds = model(feat_inputs, feat_attns)  \n",
    "    print(\".\", end=\"\")\n",
    "    preds = preds.squeeze().detach().numpy()\n",
    "    l_preds.append(preds)\n",
    "    print(\".\", end=\"\")\n",
    "    print(root_mean_squared_error(truth, preds))\n",
    "    \n",
    "\n",
    "# THEN DO A MEAN OF THE PREDICTIONS\n",
    "l_preds = np.array(l_preds).mean(0)  # this is now the mean of the ensemble predicton\n",
    "print(root_mean_squared_error(truth, l_preds))\n",
    "    \n",
    "# 1....0.4972061220307628\n",
    "# 2....0.35702121329234604\n",
    "# 3....0.4064348121115841\n",
    "# 4....0.3277875091084862\n",
    "# 5....0.4385743332602079"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f1defbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2373300214258478\n"
     ]
    }
   ],
   "source": [
    "# MEAN => 0.237 ... this is insanely good, probably has quite some overfitting :) \n",
    "print(root_mean_squared_error(truth, l_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be5fe675",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-3fae48d91a6d34b8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/hadi/.cache/huggingface/datasets/csv/default-3fae48d91a6d34b8/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f53edf2cdf24426823a4148333aa60d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28c0e5f78d334b8480039ba47f3bf14b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/hadi/.cache/huggingface/datasets/csv/default-3fae48d91a6d34b8/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eaec2fea5f34f3db0a974221fd4d9d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8b5fff7aa55402da0abc2e8ff8c49a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1...2...3...4...5..."
     ]
    }
   ],
   "source": [
    "# STEP 5: PREDICT THE COMPETITION (TEST) DATASET SCORES\n",
    "\n",
    "test_dataset = load_dataset(\"csv\", data_files= {\"test\": \"./part2_public.csv\"}, sep=\",\")[\"test\"]\n",
    "test_tokenized = test_dataset.map(tokenize_function, batched=True) \n",
    "\n",
    "l_preds = []\n",
    "for i in range(K):\n",
    "    model = models[i]    \n",
    "    print(i+1, end=\"..\")\n",
    "    preds = model(torch.tensor(test_tokenized['input_ids']), torch.tensor(test_tokenized['attention_mask']))\n",
    "    print(\".\", end=\"\")\n",
    "    preds = preds.squeeze().detach().numpy()\n",
    "    l_preds.append(preds)    \n",
    "\n",
    "# THEN DO A MEAN OF THE PREDICTIONS\n",
    "l_preds = np.array(l_preds).mean(0)\n",
    "\n",
    "# save it!\n",
    "import csv\n",
    "ids = list()\n",
    "with open(\"./part2_public.csv\", 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        ids.append(row[0])\n",
    "        #score.append(row[2])\n",
    "\n",
    "with open(\"answer-xlmr-v3.csv\", 'w') as ofile:\n",
    "    print(\"ID,MOS\", file=ofile)\n",
    "    for m,i in enumerate(ids[1:]):\n",
    "        print(str(i)+ ','+str(l_preds[m]), file=ofile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d60cae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "170px",
    "width": "184px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
